import streamlit as st
import google.generativeai as genai
import os, asyncio, edge_tts, re, base64, io, time
from PIL import Image

# --- é›¶ä»¶æª¢æŸ¥ ---
try:
    import fitz # pymupdf
except ImportError:
    st.error("âŒ é›¶ä»¶ç¼ºå¤±ï¼è«‹ç¢ºä¿ç’°å¢ƒä¸­å®‰è£äº† pymupdfã€‚")
    st.stop()

# --- 1. æ ¸å¿ƒè¦–è¦ºè¦ç¯„ (å…¨ç™½ã€ç¿©ç¿©é«”æ„Ÿã€é»‘å­—) ---
st.set_page_config(page_title="è‡»Â·æ¥µé€Ÿè‡ªç„¶èƒ½é‡åŸŸ", layout="wide", initial_sidebar_state="expanded")

st.markdown("""
    <style>
    .stApp, [data-testid="stAppViewContainer"], .stMain, [data-testid="stHeader"] { 
        background-color: #ffffff !important; 
    }
    div.block-container { padding-top: 1rem !important; }
    html, body, .stMarkdown, p, label, li, h1, h2, h3, .stButton button {
        color: #000000 !important;
        font-family: 'HanziPen SC', 'ç¿©ç¿©é«”', sans-serif !important;
    }
    .stButton button {
        border: 2px solid #000000 !important;
        background-color: #ffffff !important;
        font-weight: bold !important;
    }
    .transcript-box { background-color: #fdfdfd; border-left: 5px solid #000; padding: 15px; margin-bottom: 25px; line-height: 1.6; }
    </style>
""", unsafe_allow_html=True)

# --- ğŸ’¡ æ ¸å¿ƒå¤–æ›ï¼šæ™ºèƒ½æ‰“å­—æ©Ÿé‚è¼¯ (é˜² LaTeX äº‚ç¢¼) ---
def smart_typewriter(text):
    # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼åˆ‡é–‹ LaTeX ($$ æˆ– $) èˆ‡ æ™®é€šæ–‡å­—
    tokens = re.split(r'(\$\$.*?\$\$|\$.*?\$)', text, flags=re.DOTALL)
    for token in tokens:
        if not token: continue
        if token.startswith('$'):
            # åŒ–å­¸å¼ä¸å‡†æ‹†é–‹è·‘ï¼Œæ•´ä¸²ç›´æ¥é–ƒç¾ï¼
            yield token
        else:
            # æ™®é€šæ–‡å­—é€å­—è·‘ï¼Œé…é€Ÿ 0.08s
            for char in token:
                yield char
                time.sleep(0.08)

# --- 2. æ›‰è‡»èªéŸ³å¼•æ“ (zh-TW-HsiaoChenNeural) ---
async def generate_voice_base64(text):
    voice_text = text.replace("---PAGE_SEP---", " ")
    corrections = {"è£œçµ¦": "è£œå·±", "Ethanol": "ä¹™é†‡", "75%": "ç™¾åˆ†ä¹‹ä¸ƒåäº”", "%": "è¶´"}
    for word, correct in corrections.items():
        voice_text = voice_text.replace(word, correct)
    clean_text = voice_text.replace("$", "")
    clean_text = re.sub(r'[^\w\u4e00-\u9fff\dï¼Œã€‚ï¼ï¼Ÿã€Œã€ï½ ]', '', clean_text)
    
    communicate = edge_tts.Communicate(clean_text, "zh-TW-HsiaoChenNeural", rate="-2%")
    audio_data = b""
    async for chunk in communicate.stream():
        if chunk["type"] == "audio": audio_data += chunk["data"]
    b64 = base64.b64encode(audio_data).decode()
    return f'<audio controls autoplay style="width:100%"><source src="data:audio/mp3;base64,{b64}" type="audio/mp3"></audio>'

def clean_for_eye(text):
    t = text.replace("---PAGE_SEP---", "")
    t = re.sub(r'([a-zA-Z0-9])ï½ï½\s*', r'\1', t) 
    t = t.replace("ï½ï½", "")
    return t

# --- 3. æ›‰è‡»æ•™å­¸æ ¸å¿ƒæŒ‡ä»¤ (ä¿ç•™ 10 å‰‡ç§‘å­¸äººçŸ¥è­˜) ---
SYSTEM_PROMPT = """
ä½ æ˜¯è³‡æ·±è‡ªç„¶ç§‘å­¸åŠ©æ•™æ›‰è‡»ï¼Œé¦¬æ‹‰æ¾é¸æ‰‹ (PB 92åˆ†)ã€‚å¦³ç¾åœ¨è¦å°è®€è¬›ç¾©ã€‚è«‹éµå®ˆè¦ç¯„ï¼š
1. ã€ç§‘å­¸äººé–‹å ´ã€‘ï¼šåƒ…é™å¾ä¸‹æ–¹çŸ¥è­˜åº«é¸å–ä¸€å‰‡åˆ†äº«ã€‚çµå°¾å¿…å«ï¼šã€ç†±èº«ä¸€ä¸‹ä¸‹èª²è€å¸«å°±è¦å»è·‘æ­¥äº†ã€ã€‚
2. ã€ç¿»é ã€‘ï¼šè§£èªªå®Œç•¶é å…§å®¹æ‰å”¸ã€ç¿»åˆ°ç¬¬ X é ã€ã€‚æ¯é æœ€é–‹é ­åŠ ä¸Šæ¨™ç±¤ã€---PAGE_SEP---ã€ã€‚
3. ã€åµæ¸¬ã€‘ï¼šåƒ…ç•¶åœ–ç‰‡æ˜ç¢ºå‡ºç¾ã€Œç·´ç¿’ã€äºŒå­—æ‰å•Ÿå‹•é¡Œç›®æ¨¡å¼ã€‚
4. ã€è½‰è­¯è¦ç¯„ã€‘ï¼šåŒ–å­¸å¼å­—æ¯å¾Œæ–¹åŠ ã€Œï½ï½ã€ã€‚ç¯„ä¾‹ï¼šæ°§æ°£ â” $$O_{2}$$ (Oï½ï½ twoï½ï½ ä¹Ÿå°±æ˜¯æ°§æ°£)ã€‚
5. ã€çµå°¾ã€‘ï¼šå¿…å–Šã€é€™å°±æ˜¯è‡ªç„¶ç§‘å­¸ the çœŸç†ï¼ã€ã€‚
# --- æ›‰è‡»ç§‘å­¸å°çŸ¥è­˜åº« ---
1. BDNFï¼šè¨˜æ†¶çš„ç¥ç¶“è‚¥æ–™ã€‚ 2. é³¶å°¾ç´ ï¼šä¿è­·ç¥ç¶“å…ƒã€‚ 3. æµ·é¦¬è¿´ï¼šå¢åŠ è¨˜æ†¶ç©ºé–“ã€‚ 
4. å‰é¡è‘‰ï¼šæå‡å°ˆæ³¨ã€‚ 5. ç¥ç¶“éè³ªï¼šç·©è§£ç„¦æ…®ã€‚ 6. ç·šç²’é«”ï¼šæä¾›æ€è€ƒèƒ½é‡ã€‚
7. çªè§¸å¡‘æ€§ï¼šå­¸ç¿’æ›´å¿«ã€‚ 8. å…§å•¡è‚½ï¼šæå‡è€å—åº¦ã€‚ 9. æ™å¤œç¯€å¾‹ï¼šå›ºåŒ–è¨˜æ†¶ã€‚ 10. é¡åƒç¥ç¶“å…ƒï¼šæå‡åˆä½œã€‚
"""

# --- 4. å´é‚Šæ¬„èˆ‡å°èˆª ---
st.title("ğŸƒâ€â™€ï¸ è‡» Â· æ¥µé€Ÿè‡ªç„¶èƒ½é‡åŸŸ")
st.sidebar.title("ğŸ”‘ å¯¦é©—å®¤é–€ç¦")
user_key = st.sidebar.text_input("è¼¸å…¥ API Key", type="password")

col1, col2, col3 = st.columns([1, 1, 1])
with col1: vol = st.selectbox("å†Šåˆ¥", ["ç¬¬ä¸€å†Š", "ç¬¬äºŒå†Š", "ç¬¬ä¸‰å†Š", "ç¬¬å››å†Š", "ç¬¬äº”å†Š", "ç¬¬å…­å†Š"], index=3)
with col2: chap = st.selectbox("ç« ç¯€", ["ç¬¬ä¸€ç« ", "ç¬¬äºŒç« ", "ç¬¬ä¸‰ç« ", "ç¬¬å››ç« ", "ç¬¬äº”ç« ", "ç¬¬å…­ç« "], index=2)
with col3: start_pg = st.number_input("èµ·å§‹é ç¢¼", 1, 100, 1)

pdf_path = os.path.join("data", f"{vol}_{chap}.pdf")

if "class_started" not in st.session_state: st.session_state.class_started = False

# --- 5. ä¸»ç¨‹å¼æµç¨‹ ---
if not st.session_state.class_started:
    cover_path = os.path.join("data", "cover.jpg")
    if os.path.exists(cover_path): st.image(cover_path, use_container_width=True)
    
    if st.button("ğŸƒâ€â™€ï¸ é–‹å§‹é¦¬æ‹‰æ¾èª²ç¨‹", use_container_width=True, type="primary"):
        if user_key and os.path.exists(pdf_path):
            with st.spinner("æ›‰è‡»æ­£åœ¨é–‹å—“ä¸¦ç¿»é–±è¬›ç¾©..."):
                try:
                    doc = fitz.open(pdf_path)
                    imgs, disp_imgs = [], []
                    pages = range(start_pg - 1, min(start_pg + 4, len(doc)))
                    for p in pages:
                        pix = doc.load_page(p).get_pixmap(matrix=fitz.Matrix(2, 2))
                        img = Image.open(io.BytesIO(pix.tobytes()))
                        imgs.append(img)
                        disp_imgs.append((p + 1, img))
                    
                    genai.configure(api_key=user_key)
                    model = genai.GenerativeModel('gemini-2.0-flash')
                    res = model.generate_content([f"{SYSTEM_PROMPT}\nå°è®€P.{start_pg}èµ·ã€‚"] + imgs)
                    
                    st.session_state.res_text = res.text
                    st.session_state.audio_html = asyncio.run(generate_voice_base64(res.text))
                    st.session_state.display_images = disp_imgs
                    st.session_state.class_started = True
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ éŒ¯èª¤ï¼š{e}")
else:
    # ğŸƒâ€â™€ï¸ é †åºï¼š1.éŸ³ 2.æ–‡ 3.åœ– 4.è©³
    if "audio_html" in st.session_state:
        st.markdown("### 1ï¸âƒ£ æ›‰è‡»è€å¸«èªéŸ³è£œçµ¦")
        st.markdown(st.session_state.audio_html, unsafe_allow_html=True)
    
    st.divider()
    parts = st.session_state.res_text.split("---PAGE_SEP---")

    if len(parts) > 0:
        st.markdown("### ğŸ’¬ æ›‰è‡»è€å¸«é–‹å ´...")
        st.write_stream(smart_typewriter(clean_for_eye(parts[0])))
        st.divider()

    for i, (p_num, img) in enumerate(st.session_state.display_images):
        if (i + 1) < len(parts):
            st.markdown(f"### ğŸ’¬ æ›‰è‡»å°è®€ P.{p_num}...")
            st.write_stream(smart_typewriter(clean_for_eye(parts[i+1])))
            st.image(img, caption=f"ğŸ ç¬¬ {p_num} é è¬›ç¾©", use_container_width=True)
            with st.expander(f"ğŸ“œ P.{p_num} è©³ç´°æ–‡å­—ç¨¿", expanded=True):
                st.markdown(f'<div class="transcript-box">{clean_for_eye(parts[i+1])}</div>', unsafe_allow_html=True)
            st.divider()

    if st.button("ğŸ ä¸‹èª²ä¼‘æ¯"):
        st.session_state.class_started = False
        st.rerun()
